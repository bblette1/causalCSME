\documentclass[12pt]{article}
\title{Supporting Information for ``Addressing Confounding and Exposure Measurement Error Using Conditional Score Functions'' by Bryan S. Blette, Peter B. Gilbert, and Michael G. Hudgens}
\date{}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{caption}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{setspace}
\doublespacing
\allowdisplaybreaks

% Table commands to match Biostatistics journal format
\newcounter{tblcap}
%\renewcommand\thetblcap{\@arabic\c@tblcap}

\newsavebox{\tabbox}
\newsavebox{\tabnotesbox}
\newlength{\tablen}
\newlength{\tabnoteslen}
%\newcommand\centerlast{%
  %\advance\leftskip by 0pt plus 1fil%
  %\advance\rightskip by 0pt plus -1fil%
   %\parfillskip0pt plus 2fil\relax}

\long\def\tblcaption#1#2{\vspace*{-5pt}
\sbox{\tabbox}{#2}
\settowidth{\tablen}{\usebox{\tabbox}}
\vskip8pt\refstepcounter{tblcap}
\centering\parbox[c]{\textwidth}{
\centerlast\noindent\mbox{\noindent\centerlast
 Web Table \thetblcap.}\hskip4.5pt  {\it #1}}\\[7.75pt]
\fontsize{12}{13}\selectfont \mbox{#2}}

\long\def\tblcaptionnotes#1#2#3{
\sbox{\tabbox}{#2}
\sbox{\tabnotesbox}{\fontsize{9}{11}\selectfont #2}
\settowidth{\tablen}{\usebox{\tabbox}}
\settowidth{\tabnoteslen}{\usebox{\tabnotesbox}}
\vskip8pt\refstepcounter{tblcap}
\centering\parbox[c]{\textwidth}{
\centerlast\noindent\mbox{\noindent\centerlast
 Web Table \thetblcap.}\hskip4.5pt  {\it #1}}\\[7.75pt]
\fontsize{12}{13}\selectfont \mbox{#2}\\[5pt]
\parbox[@{}l]{\tabnoteslen}{\fontsize{8}{10}\selectfont #3}
}

\long\def\lantblcaption#1#2{
\sbox{\tabbox}{#2}
\settowidth{\tablen}{\usebox{\tabbox}}
\vskip8pt\refstepcounter{tblcap}
\centering\parbox[c]{48pc}{
\centerlast{\noindent\mbox{\noindent\centerlast
 Table \thetblcap.}\hskip4.5pt  {\it #1}}}\\[7.75pt]
\fontsize{12}{13}\selectfont \mbox{#2}}

\long\def\lantblcaptionnotes#1#2#3{
\sbox{\tabbox}{#2}
\sbox{\tabnotesbox}{\fontsize{9}{11}\selectfont #2}
\settowidth{\tablen}{\usebox{\tabbox}}
\settowidth{\tabnoteslen}{\usebox{\tabnotesbox}}
\addtolength{\tabnoteslen}{-2.5pt}
\vskip8pt\refstepcounter{tblcap}
\centering\parbox[c]{48pc}{
\centerlast\noindent\mbox{\noindent\centerlast
 Table \thetblcap.}\hskip4.5pt  {\it #1}}\\[7.75pt]
\fontsize{12}{13}\selectfont \mbox{#2}\\[5pt]
\hspace*{4pt}\parbox[@{}l]{\tabnoteslen}{\fontsize{8}{10}\selectfont #3}
}

\def\tblhead#1{\hline\\[-9pt]#1\\\hline\\[-9.75pt]}
\def\lastline{\\\hline}

\renewcommand{\figurename}{Web Figure}
\renewcommand{\thesection}{\Alph{section}}

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle

\section{Large Sample Properties}

In this appendix, the large sample properties of the proposed estimators discussed in Section 3 of the main paper are proven.

\subsection{G-formula CSM estimator}

\subsubsection{Large sample properties}

Consistency and asymptotic normality of the g-formula estimator are proven using standard estimating equation theory~\citep{stefanski2002}. The original CSM estimator is an M-estimator and the g-formula can be written as a solution to an unbiased estimating equation. Thus, the proposed g-formula CSM estimator is an M-estimator with the estimating equation vector given in equation (3).

The parameter of interest $\text{E} \{ Y(\bm{a}) \}$ appears in the last estimating equation of (3), and the proof of consistency and asymptotic normality of the g-formula CSM estimator relies on (i) the usual g-formula proof based on the causal assumptions made in Section 2 of the main paper and (ii) that the CSM estimating equations were previously shown to be unbiased~\citep{carroll2006}. In particular, (ii) implies that $\text{E}[g^{-1}(\beta_{0} + \bm{a}\beta_{a} + \bm{L}\beta_{l} + \bm{a}\beta_{al}\bm{L}^{T}) \}] = \text{E} \{ \text{E}(Y | \bm{A} = \bm{a}, \bm{L}) \}$ and then from (i) it follows that $\text{E} \{ \text{E}(Y | \bm{A} = \bm{a}, \bm{L}) \} = \text{E}[\text{E} \{ Y(\bm{a}) | \bm{L} \}] = \text{E} \{ Y(\bm{a}) \}$.

Therefore the estimating function for the parameter $\text{E} \{ Y(\bm{a}) \}$ is unbiased. Denote $\hat{\Theta}_{GF}$ as the solution to $\sum_{i=1}^{n} \psi_{GF-CSM}(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Sigma_{me}, \hat{\Theta}_{GF}) = 0$. Then under certain regularity conditions $\sqrt{n}(\hat{\Theta}_{GF} - \Theta_{GF}) \rightarrow_{d} N(\bm{0}, A^{-1}B(A^{-1})^{T})$ where $A$ and $B$ are consistently estimated by
\begin{equation*}
\hat{A} = \frac{1}{n} \sum_{i=1}^{n} \frac{d}{d\Theta_{GF}^{T}} \psi_{GF-CSM}(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Sigma_{me}, \hat{\Theta}_{GF})
\end{equation*}
\begin{equation*}
\hat{B} = \frac{1}{n} \sum_{i=1}^{n} \psi_{GF-CSM}(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Sigma_{me}, \hat{\Theta}_{GF}) \psi^{T}_{GF-CSM}(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Sigma_{me}, \hat{\Theta}_{GF})
\end{equation*}

\subsubsection{Relationship to classical causal estimators}

The CSM estimating equations reduce to the score equations for a generalized linear model (GLM) when the measurement error covariance matrix $\Sigma_{me} = 0_{m \times m}$~\citep{carroll2006}. Thus under no measurement error, the procedure described above reduces to solving a stack of estimating equations corresponding to the common practice of using the g-formula while specifying a GLM for the outcome regression, making this standard procedure a special case of the proposed estimator.

\subsection{IPW CSM estimator}

\subsubsection{Large sample properties}

The estimating equation corresponding to the parameters of interest is
\begin{equation*}
\sum_{i=1}^{n} \psi(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Sigma_{me}, \Theta_{IPW}) = \sum_{i=1}^{n} SW_{i}\{ Y_{i} - \text{E}(Y_{i} | \bm{\Delta}_{i}) \}(1, \bm{\Delta}_{i})^{T} = 0
\end{equation*}
It suffices to show that the expectation of $\psi(Y, \bm{L}, \bm{A}^{*}, \Sigma_{me}, \Theta_{IPW})$ is equal to 0. For simplicity, suppose the exposure vector consists of a single continuous-valued exposure. Non-bolded scalar notation will be used, the scalar measurement error variance will be denoted $\sigma_e^2$, and the conditional variance of $Y$ given $A$ will be denoted $\sigma^{2}$. The proof for vector $\bm{A}^{*}$ is similar. Assume the structural model $\text{E}\{ Y(a)\} = \gamma_0 + \gamma_1 a$. Recall
$$
\text{E}(Y | \Delta) = \frac{\gamma_{0} + \Delta \gamma_{1}}{1 + \gamma_{1}^2 \sigma_{e}^2  / \sigma^{2}}
$$
and $\Delta = A^* + \gamma_1 Y \sigma_e^2 / \sigma^2$. Consider the intercept component of the estimating equation. The goal is to show $\text{E} [SW \{Y - \text{E}(Y|\Delta) \} ]= 0$, or equivalently
\begin{equation}
\text{E}( SW \, Y )= \text{E}\{ SW \, \text{E}(Y|\Delta) \}
\end{equation}
First consider the left side of (1):
\begin{align*}
\text{E}( SW \, Y ) &= \text{E} \left \{ \frac{f(A^*;\xi)}{f(A^*|L;\zeta)} Y \right \} \\
& = \text{E}_L \left \{ \int_{a^*} \frac{f(a^*;\xi)}{f(a^*|L;\zeta)} \text{E}(Y|A^*=a^*,L) dF(a^*|L) \right \} \\
& = \text{E}_L \left \{ \int_{a^*}  \text{E}(Y|A^*=a^*,L) f(a^*;\xi) da^* \right \} \\
& = \int_{a^*}  \text{E}(Y|A^*=a^*) f(a^*;\xi) da^* = \text{E}(Y)
\end{align*}
Next consider the right side of (1):
\begin{align*}
\text{E} \{ SW \, \text{E}(Y|\Delta) \} &= \text{E} \left \{ \frac{f(A^*;\xi)}{f(A^*|L;\zeta)} \text{E}(Y|\Delta) \right \} \\
&= \text{E}_L \left [ \int_{a^*} \frac{f(a^*;\xi)}{f(a^*|L;\zeta)} \text{E}\{\text{E}(Y|\Delta)|A^*=a^*,L\} dF(a^*|L) \right ]\\
&= \text{E}_L \left [ \int_{a^*}  \text{E}\{\text{E}(Y|\Delta)|A^*=a^*,L\} f(a^*;\xi) da^* \right ]\\
&= \int_{a^*}  \text{E} \bigg(
\frac{\gamma_{0} + \Delta \gamma_{1}}{1 + \gamma_{1}^2 \sigma_{e}^2  / \sigma^{2}}
|A^*=a^* \bigg) f(a^*;\xi) da^*\\
&= (1 + \gamma_{1}^2 \sigma_{e}^2  / \sigma^{2})^{-1} \int_{a^*}  \text{E}[
\{ \gamma_{0} + (A^* + \gamma_1 Y \sigma_e^2 / \sigma^2) \gamma_{1}\}
|A^*=a^* ] f(a^*;\xi) da^*\\
&=
(1 + \gamma_{1}^2 \sigma_{e}^2  / \sigma^{2})^{-1}\{ \gamma_0 + \gamma_1 \text{E}(A^*) + \gamma_1^2
\text{E}(Y) \sigma_e^2 / \sigma^2\}
\end{align*}
Thus we need to show $\text{E}(Y) = \gamma_0 + \gamma_1 \text{E}(A^*) = \gamma_0 + \gamma_1 \text{E}(A)$ to complete the proof. To see this, note
\[
\text{E}(Y) = \text{E} \{ Y(A) \} = \int_a \text{E}\{ Y(a) \} dF(a) = \gamma_0 + \gamma_1 \text{E}(A)
\]

The proof for the other component of the estimating equation,
\[
\text{E} \bigg[SW \{ Y - \text{E}(Y | \Delta)\} \Delta \bigg] = 0
\]
is similar. Thus, the proposed IPW CSM estimator is consistent and asymptotically normal. The estimator of the asymptotic variance of the IPW CSM estimator is given by the usual sandwich estimator as described in the previous section.

\subsubsection{Relationship to classical causal estimators}

If the measurement error covariance matrix $\Sigma_{me} = \bm{0}_{m \times m}$, then $\bm{A}^{*} = \bm{A}$ and the sufficient statistic $\bm{\Delta}$ reduces to the observed exposure vector. Then the IPW estimator reduces to the form $\sum_{i=1}^{n} \psi(Y_{i}, \bm{L}_{i}, \bm{A}^{*}_{i}, \Theta_{IPW}) = 0$ where:

\begin{equation*}
    \psi(Y, \bm{L}, \bm{A}^{*}, \Theta_{IPW}) =
    \begin{bmatrix}
      \psi_{PS}(\bm{L}, \bm{A}^{*}, \zeta) \\
       SW\{ Y - \text{E}(Y | \bm{A}^{*}) \} (1, \bm{A}^{*})^{T} \\
       SW \left [ \phi - \frac{ \{Y - \text{E}(Y | \bm{A}^{*}) \}^{2}}{Var(Y | \bm{A}^{*}) / \phi} \right ]
    \end{bmatrix}
\end{equation*}
This is exactly the score function vector for a GLM weighted by $SW$. Thus, an IPW estimator fit using a weighted GLM for outcome $Y$ is a special case of the proposed IPW CSM estimator where there is no measurement error present.

\subsection{DR CSM Estimator}

\subsubsection{Large Sample Properties}

Once again, consistency and asymptotic normality of the proposed estimator is proven using M-estimator theory. Recall from Section 3.4 that this estimator is a solution to the estimating equation $\sum_{i=1}^{n} \psi_{DR-CSM}(Y_{i}, \bm{L}_{i}, \bm{A}_{i}^{*}, \Sigma_{me}, \Theta_{DR}) = 0$, where $\Theta_{DR} = (\zeta, \Theta_{GF})$ and
\begin{equation*}
    \psi_{DR-CSM}(Y, \bm{L}, \bm{A}^{*}, \Sigma_{me}, \Theta_{DR}) =
    \begin{bmatrix}
        \psi_{PS}(\bm{L}, \bm{A}^{*}, \zeta) \\
       SW\{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}) \} (1, \bm{L}, \bm{\Delta}, \bm{L} \otimes \bm{\Delta})^{T} \\
        SW[\phi - \{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}) \}^{2} / \{ \text{Var}(Y | \bm{L}, \bm{\Delta}) / \phi \}] \\
        \beta_{0} + \bm{a}\beta_{a} + \bm{L}\beta_{l} +
        \bm{a}\beta_{al}\bm{L}^{T} - \text{E} \{ Y(\bm{a}) \}
    \end{bmatrix}
\end{equation*}

First, suppose that the outcome regression is correctly specified. Then $\text{E}( \beta_{0} + \bm{a}\beta_{a} + \bm{L}\beta_{l} + \bm{a}\beta_{al}\bm{L}^{T}) = \text{E} \{ \text{E}(Y | \bm{A} = \bm{a}, \bm{L}) \} = \text{E}[\text{E} \{ Y(\bm{a}) | \bm{L} \}] = \text{E} \{ Y(\bm{a}) \}$ such that $\text{E}[(\beta_{0} + \bm{a}\beta_{a} + \bm{L}\beta_{l} + \bm{a}\beta_{al}\bm{L}^{T}) - \text{E} \{ Y(\bm{a) \}] = 0$.

Now suppose instead that the propensity score model(s) are correctly specified. As in the IPW proof, suppose there is one scalar exposure (the proof for vector $\bm{A}$ is similar) and that the stabilized weights are given by a ratio of densities. The goal is to again show that $\text{E}[(\beta_{0} + a\beta_{a} + \bm{L}\beta_{l} + a\beta_{al}\bm{L}^{T}) - \text{E} \{ Y(a) \}] = 0$. However, the $\beta$ terms are now estimated from a weighted outcome regression model where the outcome regression form may be mis-specified.

In order to show this, consider the intercept element of the second row of the estimating equation and define $\beta^{*}$ such that
\begin{align*}
0 &= E \left [ \frac{f(A^{*}) \{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) \}}{f(A^{*} | \bm{L}; \hat{\zeta})} \right ] \\
&= \int \int \frac{f(a^{*})\text{E} [ \{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) \} | A^{*} = a^{*}, \bm{L} = \bm{l} ]}{f(a^{*} | \bm{l}; \hat{\zeta})} dF(\bm{l} | a^{*}) f(a^{*})da^{*} \\
&= \int f(a^{*}) \int \{\text{E}(Y | A^{*} = a^{*}, \bm{L} = \bm{l}) - \text{E} \{ \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) | A^{*} = a^{*}, \bm{L} = \bm{l} \} dF(\bm{l}) da^{*}
\end{align*}
since the propensity score model is correctly specified with estimated parameters $\hat{\zeta}$.

We have already assumed that $Y | A = a, \bm{L} = l \sim N(\beta_{0} + a\beta_{a} + \bm{l}\beta_{l} + a\beta_{al}\bm{L}^{T}, \sigma^{2})$. Thus, $Y | A^{*} = a^{*}, \bm{L} = \bm{l}$ or equivalently, $Y | A + \epsilon = a^{*}, \bm{L} = \bm{l}$ follows a Normal distribution with mean $\beta_{0} + a^{*}\beta_{a} + \bm{l}\beta_{l} + a^{*}\beta_{al}\bm{L}^{T}$ since $\epsilon \sim N(0, \sigma^{2}_{me})$. (I think this should be true because we assume non-differential ME, but how to show more concretely?). Then
\begin{align*}
\int \text{E}(Y | A^{*} = a^{*}, \bm{L} = \bm{l})dF(\bm{l}) &= \int \text{E}(Y | A = a^{*}, \bm{L} = \bm{l})dF(\bm{l}) \\
&= \int \text{E}\{ Y(a^{*}) | A = a^{*}, \bm{L} = \bm{l} \} dF(\bm{l}) \\
&= \int \text{E}\{ Y(a^{*}) | \bm{L} = \bm{l} \} dF(\bm{l}) \\
&= \text{E}\{ Y(a^{*}) \}
\end{align*}
under causal consistency and conditional exchangeability. Now recall that under the assumed identity link,
\begin{equation*}
\Delta = A^{*} + (\beta^{*}_{a} + \bm{L}\beta^{*}_{al}) \Sigma_{me}Y / \sigma^{2}
\end{equation*}
\begin{equation*}
\text{E}(Y | \bm{L}, \Delta; \beta^{*}) = \frac{\beta^{*}_{0} + \bm{L}\beta^{*}_{l} + \Delta \cdot (\beta^{*}_{a} + \bm{L}\beta^{*}_{al})}{1 + (\beta^{*}_{a} + \bm{L}\beta^{*}_{al}) \Sigma_{me} (\beta^{*}_{a} + \bm{L}\beta^{*}_{al})^{T} / \sigma^{2}}
\end{equation*}
where a mis-specified outcome regression could correspond to missing or extraneous covariates, interaction terms mistakenly set to 0, etc.

Consider $\text{E} \{ \text{E}(Y | \bm{L}, \Delta; \beta^{*}) | A^{*} = a^{*}, \bm{L} = \bm{l} \}$ and plug in $\Delta$ such that
\begin{align*}
&\text{E} \{ \text{E}(Y | \bm{L}, \Delta; \beta^{*}) | A^{*} = a^{*}, \bm{L} = \bm{l} \} \\
&= \frac{\beta_{0}^{*} + \bm{l}\beta_{l}^{*} + (a^{*} + (\beta_{a}^{*} + \bm{l}\beta_{al}^{*}) \sigma^{2}_{me} E( Y | A^{*} = a^{*}, \bm{L} = \bm{l}) / \sigma^{2}) \cdot (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})}{1 + \sigma^{2}_{me} (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})^{2} / \sigma^{2}} \\
&= \frac{\beta_{0}^{*} + \bm{l}\beta_{l}^{*} + a^{*}\beta_{a}^{*} + a^{*}\beta_{al}^{*}\bm{l}^{T} + ((\beta_{a}^{*} + \bm{l}\beta_{al}^{*}) \sigma^{2}_{me} (\beta_{0}^{*} + \bm{l}\beta_{l}^{*} + a^{*}\beta_{a}^{*} + a^{*}\beta_{al}^{*}\bm{l}^{T}) / \sigma^{2}) \cdot (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})}{1 + \sigma^{2}_{me} (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})^{2} / \sigma^{2}} \\
&= \frac{(\beta_{0}^{*} + \bm{l}\beta_{l}^{*} + a^{*}\beta_{a}^{*} + a^{*}\beta_{al}^{*}\bm{l}^{T}) \cdot \{ 1 + \sigma^{2}_{me} (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})^{2} / \sigma^{2} \}}{1 + \sigma^{2}_{me} (\beta_{a}^{*} + \bm{l}\beta_{al}^{*})^{2} / \sigma^{2}} \\
&= \beta_{0}^{*} + \bm{l}\beta_{l}^{*} + a^{*}\beta_{a}^{*} + a^{*}\beta_{al}^{*}\bm{l}^{T}
\end{align*}

This implies that $\int \text{E} \{ \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) | A^{*} = a^{*}, \bm{L} = \bm{l} \} dF(\bm{l}) = E(\beta_{0}^{*} + \bm{L}\beta_{l}^{*} + a^{*}\beta_{a}^{*} + a^{*}\beta_{al}^{*}\bm{L}^{T})$. As stated before, the second row of the estimating equation implies that the following relation holds:
\begin{equation*}
\int f(a^{*}) \int \{\text{E}(Y | A^{*} = a^{*}, \bm{L} = \bm{l}) - \text{E} \{ \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) | A^{*} = a^{*}, \bm{L} = \bm{l} \} dF(\bm{l}) da^{*} = 0
\end{equation*}

The numerator of the weights $f(a^{*})$ was assumed to correspond to a non-degenerate distribution and $a^{*}$ is an arbitrary constant. Thus, the $\beta^{*}$ corresponding to the solution of the weighted outcome regression, even if the regression form is mis-specified, will yield $\text{E}[(\beta^{*}_{0} + \bm{a}\beta^{*}_{a} + \bm{L}\beta^{*}_{l} + \bm{a}\beta^{*}_{al}\bm{L}^{T}) - \text{E} \{ Y(\bm{a}) \}] = 0$ and the fourth row of the estimating equation is unbiased. Since the estimating equation is unbiased if either the propensity or outcome model is correctly specified, the proposed estimator is doubly-robust.

\vspace{3cm}

(I also tried the route of plugging in $A^{*} = A + \epsilon$ in the beginning and integrating over three random variables, but I wasn't able to cancel the denominator this way)

\begin{align*}
0 &= E \left [ \frac{f(A^{*}) \{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) \}}{f(A^{*} | \bm{L}; \zeta)} \right ] \\
&= E \left [ \frac{f(A + \epsilon) \{ Y - \text{E}(Y | \bm{L}, \bm{\Delta}; \beta^{*}) \}}{f(A + \epsilon | \bm{L}; \zeta)} \right ] \\
&= \text{not clear how denominator will ever be cancelled unless we integrate} \\
& \;\;\;\;\; \text{over something that is equivalent to the above?}
\end{align*}




Old below (what we submitted to Biometrics):

The large sample properties of the DR CSM estimator follow directly from the results in A.1 and A.2 and from \citet{kang2007}. In particular, when the outcome regression is correctly specified, the weights will affect the efficiency of the estimator, but it will remain consistent. Likewise, when the propensity model is correctly specified, the weighting will ensure that the model is fit in a pseudo-population where no confounding is present. Thus, the estimated outcome model coefficients will converge to the MSM parameters (as long as the outcome model includes an intercept and main effect for exposure, which should be standard for applying this estimator) and the estimator will again be consistent. Therefore, this estimator is doubly-robust. The estimator of the asymptotic variance is given by the usual sandwich variance estimator.

\subsubsection{Relationship to classical causal estimators}

Under no measurement error the CSM equations reduce to the score equations of a GLM (here a linear model). Thus the proposed DR CSM estimator will reduce to the DR estimator described in \citet{kang2007} where the specified outcome regression is a linear model.

\subsection{Uniqueness of EE solutions}

The proofs above showing consistency and asymptotic normality of the proposed estimators require each set of estimating equations to have a unique solution. Prior work has shown that similar conditional score equations do not always have unique solutions, but that multiple solutions are very rare in practice~\citep{stefanski1987}. In the various simulations of this paper, multiple solutions or estimator divergence were encountered with similar rarity, at most 1 or 2 times per 1000 simulations, unless considering extreme data generating mechanisms. Thus, the estimators should have good behavior in general, but practitioners should be aware of rare instances of multiple solutions, unusual estimates, and/or root-solving algorithm divergence errors.

\section{Two-Phase Sampling}

\subsection{Two-phase sampling method}

Many studies (including the HVTN 505 trial) use a two-phase sampling design. Such a design is particularly useful when the primary exposure(s) and outcome are easy to measure, but exposures and covariates of secondary interest are expensive or difficult to measure. Because each of the proposed methods above belongs to the estimating equation framework, it is straightforward to incorporate previously described methods for causal inference from studies with two-phase sampling. In this section, one such approach is demonstrated using a simulation study. In particular, for this simulation and the application section analysis, a simple inverse probability of sampling weights method is used~\citep{wang2009}.

The method is implemented by weighting each individual's contribution to the estimating equations by the inverse probability of selection for the second-phase of the study (multiplying treatment weights by sampling weights for the IPW-CSM and DR-CSM estimators) and restricting the analysis to those selected. This method is well-suited for the subset of the HVTN 505 trial that is the focus of Section 5 of the main paper, particularly because all exposures of interest were measured in the second-phase sub-sample and no exposures were measured in the full sample.

\subsection{Two-phase sampling simulations}

The structure of the first simulation study described in Section 4 of the main paper is replicated, but under a two-phase sampling design. In particular, a case-cohort design is used where the exposure is measured for a random sub-cohort as well as for every case. This is done for a sample size of $n=2000$ under three scenarios, with sub-cohorts of size $5\%$, $10\%$ and $25\%$. The results of 2000 simulation runs are presented in Web Figure 1 and Web Table 1.

The methods perform similar to the full-sampling simulation provided in the main paper, although there is some bias and under-coverage when the sub-cohorts are smaller, likely due to a low effective sample size. In addition, the estimators failed to converge in some of the small sub-cohort settings. However, the DR CSM estimator with sampling weights converged in all analyses presented in Section 5 of the main paper.

\section{Additional Simulations}

In this section, additional simulations are presented under two assumption violations: (i) when positivity doesn't hold and (ii) when measurement error doesn't follow a classical additive model.

\subsection{Positivity violation}

To evaluate the proposed g-formula CSM method under positivity violation, the general structure of the first simulation study from Section 4 of the main paper is replicated almost exactly. A moderate positivity violation is created by changing how the treatment $A_{1}$ is generated from $\mathcal{N}(2 + 0.3L_{1} - 0.5L_{2}, 0.6)$ to $\mathcal{N}(2 + 0.3L_{1} - 0.5L_{2}, 0.35)$. This breaks the phenomenon of mostly overlapping treatment values experienced by simulated subjects with different covariate values, although in a technical sense is not a structural violation of positivity since the distributions would have the same support given infinite sample size. The results of the simulation study are presented in Web Figure 2 and Web Table 2, following the same format as Table 1 and Figure 2 in the main paper.

The results overall look similar to that in Table 1 of the main paper. There is some bias and undercoverage for the proposed g-formula CSM methods, but the proposed method still generally performs better than the comparator methods in this scenario. Some bias at the extremes of the exposure support is expected and not fully due to the positivity violation, given that there is very little data at the extremes with the new data generating mechanism. A reasonable range to evaluate the methods would be from 0.5 to 3.5 in these simulations.

Positivity violations become more likely with more treatment variables and with treatment variables that are continuous or take on many values. In these settings positivity should receive just as much scrutiny as the conditional exchangeability assumption. If positivity is implausible, it may be possible to define an estimator in our setting similar to that described in \citet{neugebauer2005} which was robust to their analogous "experimental treatment assumption".

\subsection{Non-additive measurement error}

Next the proposed methods are evaluated when treatment measurement error does not follow the classical additive model. In particular, the second simulation study from Section 4 of the main paper is replicated, but the simulation of mismeasured treatment $A^{*}_{3}$ is changed such that it follows a multiplicative error model simulated as $A_{3}^{*} = A_{3} \epsilon_{me_{1}}$ where $\epsilon_{me_{1}} \sim \mathcal{N}(1, 0.1)$. The methods are still performed assuming additive measurement error with known measurement error covariance as specified in section 4 of the main paper, and the $A^{*}_{3}$ distribution under this additive ME assumption is similar to the distribution under the true multiplicative ME generative model. The results are presented in Web Table 3. The proposed IPW CSM method continued to perform well for treatments $A_{1}$ and $A_{2}$ for which the assumptions hold, but exhibited strong bias for the $A_{3}$ effect. Practitioners of the proposed methods should be cautious that if classical additive measurement error models do not hold for their exposures, they may get worse results than even standard regression models.

\section{More complex model specifications for the IPW CSM estimator}

The proposed IPW CSM estimator assumes a linear marginal structural model form. While this is helpful to match the conditional score framework described in Section 3.1, it may be too restrictive for some potential applications. To this end we note that transformations of elements of $\bm{A}$ and interactions thereof can be included in the MSM specification as long as they are either assumed to be correctly measured or assumed to follow a classical additive measurement error model. For example, if an exposure is strictly positive, then its log transform may be assumed to follow an additive measurement error model and can be included in the model. In general, transformations of correctly measured exposures can be included in the MSM specification without restriction.

Finally, while conditional score functions are somewhat limited in scope in terms of model specification, the related method of corrected score functions has been extended to problems of additive but non-normal measurement error~\citep{buzas1996} and to non-additive measurement models in certain cases (\citealp{nakamura1990}; \citealp*{li2004}). Describing how to use such corrected score functions to estimate causal parameters could be the focus of future work in this area.

\newpage
\begin{Large}

\begin{table}[h]
\tblcaption{Simulation study for case-cohort design. Bias: 100 times the average bias across simulated data sets for each method; ASE: 100 times the average of estimated standard errors; ESE: 100 times the standard deviation of parameter estimates; Cov: Empirical coverage of 95$\%$ confidence intervals for each method, rounded to the nearest integer. \% FTC: Percent of simulations which failed to converge, rounded to the nearest integer.}
{\tabcolsep=6.25pt
\begin{tabular}{@{}lcrrrr@{}}
\tblhead{Sub-cohort Size & Bias & ASE & ESE & Cov & \% FTC}
5\% & 4.1 & 8.7 & 7.1 & 84\% & 6\% \\
10\% & 2.4 & 6.3 & 5.6 & 90\% & 2\% \\
25\% & 0.9 & 4.1 & 3.9 & 94\% & 0\%
\lastline
\end{tabular}}
\end{table}

\end{Large}
\newpage

\begin{table}[h]
\tblcaption{Simulation study under positivity violation. Bias, ASE, ESE, and Cov defined as in Web Table 1.}
%\caption*{Appendix Table 1: Simulation study under positivity violation}
{\tabcolsep=4.25pt
\begin{tabular}{@{}lrrrr@{}}
\tblhead{Estimator & Bias & ASE & ESE & Cov}
Regression & -69.8 & 21.5 & 21.8 & 11\% \\
CSM & -17.0 & 80.3 & 68.5 & 95\% \\
G-formula & -6.3 & 3.0 & 3.0 & 44\% \\
G-formula CSM & 2.2 & 9.3 & 9.1 & 92\%
\lastline
\end{tabular}}
\end{table}

\newpage

\begin{table}[h]
\tblcaption{Simulation study under non-additive measurement error. Bias, ASE, ESE, and Cov defined as in Web Table 1.}
{\tabcolsep=4.25pt
\begin{tabular}{@{}clrrrr@{}}
    %\begin{tabular}{clrrrr}
       \tblhead{Parameter & Estimator & Bias & ASE & ESE & Cov}
$\gamma_{1}$ & Regression & 4.9 & 14.0 & 13.3 & 93\% \\
$\gamma_{1}$ & CSM & 21.7 & 20.0 & 19.3 & 82\% \\
$\gamma_{1}$ & IPW & -9.9 & 9.1 & 9.0 & 79\% \\
$\gamma_{1}$ & IPW CSM & 0.6 & 13.0 & 12.7 & 95\% \\[4pt]
$\gamma_{2}$ & Regression & 10.3 & 28.0 & 27.7 & 93\% \\
$\gamma_{2}$ & CSM & 8.7 & 29.4 & 28.4 & 93\% \\
$\gamma_{2}$ & IPW & 0.0 & 20.0 & 19.7 & 94\% \\
$\gamma_{2}$ & IPW CSM & -0.9 & 20.4 & 20.1 & 95\% \\[4pt]
$\gamma_{3}$ & Regression & 1.9 & 15.8 & 15.4 & 94\% \\
$\gamma_{3}$ & CSM & -35.0 & 33.5 & 32.7 & 86\% \\
$\gamma_{3}$ & IPW & 4.7 & 15.9 & 15.5 & 93\% \\
$\gamma_{3}$ & IPW CSM & -29.0 & 33.0 & 32.0 & 88\%
         \lastline
    \end{tabular}}
\end{table}

\newpage

\begin{figure}
\centering
\includegraphics[width=6in]{app_fig1.pdf}
\caption{Estimated dose-response curve bias for the DR CSM method compared across three sub-cohort sizes. Bias refers to the average bias across 2,000 simulated data sets for each method evaluated at each point on the horizontal axis $a = (0, 0.2, 0.4, ..., 4)$.}
\end{figure}

\newpage

\begin{figure}
\centering
\includegraphics[width=6in]{app_fig2_updated.pdf}
\caption{Estimated dose-response curve bias for each of the four methods under positivity violation. Bias refers to the average bias across 2,000 simulated data sets for each method evaluated at each point on the horizontal axis $a = (0, 0.2, 0.4, ..., 4)$.}
\end{figure}

\clearpage
\newpage

\bibliographystyle{biom}
\bibliography{refs}

\end{document}
